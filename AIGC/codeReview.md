

### code-review系统

### 介绍
- 主要以“采纳率” 为基本的指标，同时考虑了大模型的使用成本，以及系统的集成和易用性、学习和适应能力等，通过综合运用了RAG技术，精细化的prompt书写，链编排，实现了一个自动化CR系统，可以自动更新知识库，并包含数据看板功能。
主要评审方向有： 
1. 业务逻辑准确性
2. 是否符合团队规范
3. 代码书写是否标准等。


### 主要指标
- 采纳率：可一定程度说明准确率/覆盖率/误报率，是一个比较中肯的指标
- 响应时间 （暂不关注）
- 成本效益（tokens消耗）
- 集成和易用性
- 学习和适应能力：强大的学习和适应能力确保系统在不断变化的开发环境中保持有效性
- 用户满意度

### cr维度
以采纳率为基本的指标，帮助开发者识别以下问题，并实现数据看板。
1. 业务逻辑准确性，是否有bug风险。
2. 是否符合团队的规范。如：是否对页面样式标示scoped，是否将图片传入CDN等等，是否动态使用域名。
3. 代码书写是否标准：
- 代码语义化以及拼写错误
- 简化逻辑
- 错误处理和提示是否注重体验
- 硬编码
- 性能优化




### 实现细节
1. 协作：集成到code官网，涉及到跨团队协作，获取其他团队支持。（掌握整个流程需要哪些API支持，清晰的说明需求。）
2. 大模型调试相关：
- 理解向量库分段规则以及匹配规则，以便创建更好的知识库。
- 提示词的书写，保证评论格式有效，内容全面 + 准确，主要的技巧


基础：
- 在提示词中加入重要的细节和背景信息 
- 在system中要求模型扮演特定的角色 
- 使用xml标签/章节标题等分隔符区别不同的文本内容 
- 正确示例 和 badcase 示例 


进阶：
- 明确指出完成任务需要进行的步骤
- 模型自动prompt调优 
调试时，可以让模型给出结果的同时，标明理由 
- 思维链方式。一步步思考。
- 减少幻觉的方式：复述一下原文本。


3. 知识库：
- 根据线上问题进行具体的分析，补充知识库。
- 根据人工评审，补充知识库。

4. 集成和易用性：将评审系统集成到code merge request中，更方便获取采纳率。
5. 成本效益：通过诊断智能体，初步排查问题，减少检索内容，节约tokens。另外将一些文件类型（md，json）进行过滤
6. 学习和适应能力：实现人工评审自动升级为知识库物料，进行人工批量审核。确保系统在不断变化的开发环境中保持有效性。


### 当前存在的问题
1. 将评审系统集成到merge request中，只能评论代码diff片段，上下文信息不足。（可以考虑集成vscode插件）。
2. 针对业务逻辑准确性的判断，目前还没有比较标准的方案，目前的想法通过业务注释说明结合代码实现去进行评审。